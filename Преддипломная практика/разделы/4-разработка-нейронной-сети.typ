#import "@local/gost732-2017:0.4.2": *
#import "@local/bmstu:0.3.0": *
#set math.equation(numbering: "(1)")

= Разработка нейронной сети
== Выбор архитектуры
Для задачи автоматического отбора фотографий требовалось решение, которое одновременно устойчиво выделяет технические дефекты на разных сценах, достаточно лёгкое для интеграции в приложение и выдаёт раздельные оценки по каждому дефекту, чтобы затем можно было настраивать пороги и логику отбора изображений.

С учётом этого была выбрана архитектура по схеме «общая основа + несколько выходов». Общая часть (основа) извлекает универсальные признаки изображения, а далее идут отдельные выходные блоки, каждый из которых отвечает за свой дефект. Такой подход особенно удобен в задаче, где дефекты могут встречаться независимо друг от друга: фотография может быть одновременно нерезкой и недоэкспонированной, либо иметь только один дефект. Поэтому вместо выбора одной оценки хорошо/плохо используется многометочная постановка: сеть выдаёт три независимые оценки - по нерезкости, недосвету и пересвету.

На практике входное изображение подаётся в основу EfficientNetB0 (предобученную на ImageNet, без верхней классификационной части), далее применяется глобальное агрегирование признаков и регуляризация (dropout). Затем от общего вектора признаков отходят три параллельных выхода, каждый из которых предсказывает один логит (одно число) - отдельно для нерезкости, недосвета и пересвета. Таким образом, начальная версия нейронной сети представляла собой EfficientNetB0 + 3 выхода по одному нейрону. На выходе сеть формирует три значения, каждое из которых отражает наличие или отсутствие соответствующего дефекта.

Итоговая архитектура схематично представлена на рисунке @общая-архитектура.

#рис(image("../материалы/общая-архитектура.png", width: 80%))[ Архитектура нейронной сети ] <общая-архитектура>

Выбор EfficientNetB0 как основы был сделан на базе результатов научно-исследовательской работы, выполненной в 7 семестре. В рамках НИРа сравнивались несколько популярных архитектур по трём критериям: число параметров, вычислительная сложность и итоговое качество. Рассматривались, в частности, ResNet18, MobileNetV2, EfficientNet-B0 и более тяжёлая архитектура на трансформерах (TinyViT-21M). Сравнение показало, что тяжёлые модели действительно могут давать более высокую точность, но требуют существенно больше вычислений и ресурсов. При этом EfficientNet-B0 продемонстрировала лучший баланс: по качеству она заметно превосходила более простые варианты при умеренном размере и вычислительной нагрузке. Для задачи преддипломной практики этот компромисс оказался оптимальным: модель остаётся достаточно компактной для обучения, экспериментов и встраивания в десктопное приложение, но при этом обеспечивает хороший уровень точности и устойчивости.

// Архитектура EfficientNetB0 представлена на рисунке @архитектура-B0.

// #рис(image("../материалы/B0-архитектура.png", width: 100%))[ Архитектура EFficientNetB0 ] <архитектура-B0>

\
\
\
\
\

== Реализация нейронной сети
=== Первое поколение
Обучение организовано через TensorFlow с использованием конвейера tf.data, так как разметка задаётся таблицами train.csv и val.csv, а не структурой папок вида класс/изображения. На этапе подготовки данных путь к файлу считывается из CSV, затем изображение загружается функцией tf.io.read_file и декодируется универсальным декодером tf.image.decode_image, который позволяет работать с форматами JPG/PNG/BMP. После декодирования изображение приводится к типу float32 и нормируется в диапазон [0; 1], а далее масштабируется до фиксированного размера 384×512 пикселей. Такой размер был выбран как компромисс между сохранением деталей дефектов (в первую очередь нерезкости) и ограничениями по ресурсам видеопамяти при обучении. Для обучающей выборки дополнительно применяется перемешивание, затем данные группируются в пакеты размером 16 изображений и подаются на обучение с предварительной подгрузкой, что уменьшает простои вычислений из-за ввода-вывода.

Выход основы (EfficientNet-B0) представляет собой пространственную карту признаков, которая преобразуется в вектор с помощью глобального усредняющего пуллинга (GlobalAveragePooling2D). Далее применяется Dropout с вероятностью 0.2: этот слой на обучении случайно "отключает" часть нейронов и тем самым снижает риск переобучения. После этого реализованы три независимые "головы" - по одному полносвязному слою на каждый дефект. Важно, что выходы голов являются логитами: логит - это значение до применения сигмоиды, а вероятность дефекта получается применением функции sigmoid(logit).

В качестве функции потерь используется бинарная кросс-энтропия с параметром from_logits=True. Это означает, что функция потерь сама применяет сигмоиду внутри себя и корректно работает с логитами. Для контроля качества в процессе обучения применяется метрика AUC, причём в многометочном варианте. Бинарной кросс-энтропии рассчитывается по формуле @бинарная-кросс-энтропия.

$ L(y,p) = -[y log(p) + (1-y)log(1-p)], $ <бинарная-кросс-энтропия>
#v(-1.5em)
где $L(y,p)$ - значение функции потерь,\
$y$ - истинная метка ( $y \in {0,1}$ ),\
$p$ - предсказанная моделью вероятность класса 1 ( $0 < p < 1$ ).

Обучение первого поколения проводилось в два этапа. На первом этапе обучались только три выходные головы, а основа EfficientNetB0 была заморожена (backbone.trainable=False). Скорость обучения на этом этапе была выбрана 10^(-3). На втором этапе основа размораживалась полностью (backbone.trainable=True) и выполнялось дообучение всей сети с уменьшенной скоростью обучения 110^(-4). Уменьшение шага здесь принципиально: дообучение предобученной основы требует более аккуратных обновлений, иначе можно быстро получить деградацию признаков и нестабильность обучения. Размер пакета 16 выбран исходя из практического баланса: он достаточно велик для приемлемой стабильности градиентов, но при размере входа 384×512 не приводит к переполнению видеопамяти на видеокарте "домашнего" компьютера.

Динамика обучения показывает, что выбранная схема действительно даёт прирост качества. По итогам первого этапа (5-я эпоха обучения только голов) обучающая AUC достигла 0.6063 при значении функции потерь 0.4276, а на проверочной выборке AUC составила 0.7151 при val_loss = 0.4325. После перехода ко второму этапу и дообучения основы качество на проверке выросло существенно выше. В конце обучения достигнуты значения auc = 0.8048, loss = 0.3496, val_auc = 0.8627, val_loss = 0.3205. Таким образом, именно после дообучения основы модель значительно лучше отделяет дефектные изображения от качественных по всем трём меткам. Конкретные значения loss и auc в зависимости от эпох прежставлены на рисунке @журнал-первое.

#рис(image("../материалы/первое поколение.jpg", width: 80%))[ Значения loss и AUC первого поколения ] <журнал-первое>

На графиках обучения заметна характерная проблема: проверочная функция потерь val_loss ведёт себя нестабильно и даёт резкие всплески на последних 5 эпохах, несмотря на общий рост AUC. Это поведение связано с тем, что при полном размораживании основы начинают активно обновляться слои пакетной нормализации BatchNorm. BatchNorm (пакетная нормализация) использует статистики текущего пакета и поддерживает скользящие оценки среднего и дисперсии, которые затем влияют на поведение модели на проверке и при реальном использовании. При небольшом размере пакета (в данном случае 16) оценки статистик получаются шумными, а их обновление может приводить к тому, что модель подстраивается под особенности обучающих пакетов и временно ухудшается на проверке. Визуально это проявляется скачками val_loss и колебаниями val_auc. В дальнейшем эта проблема была решена заморозкой BatchNorm на этапе дообучения основы. Графики обучения представлены на рисунке @первое-графики.

#рис(image("../материалы/первое_поколение_training_curves.png", width: 70%))[ Графики ключевых метрик первого поколения ] <первое-графики> 

Дополнительно качество было оценено отдельным скриптом на проверочной выборке в терминах точности (т.е. в более понятных человеку процентах угадывания) при фиксированном пороге решения. Получены значения: общая точность по всем меткам составила 0.8333, отдельно по дефектам - 0.7492 для blur, 0.8725 для under и 0.8784 для over. Результаты проверки точности представлены на рисунке @первое-точность.

#рис(image("../материалы/первое_поколение_accuracy.jpg", width: 80%))[ Точность правильных предсказаний первого поколения ] <первое-точность>

В целом первое поколение подтвердило работоспособность выбранного направления: трёхголовая архитектура на EfficientNetB0 обучается на синтетических искажениях и демонстрирует высокую способность различать дефекты, а двухэтапная схема обучения существенно улучшает качество по сравнению с обучением только выходных слоёв. Одновременно были выявлены практические ограничения, связанные с нестабильностью проверки при дообучении основы из-за BatchNorm, что стало основанием для последующих улучшений во втором поколении модели. Программный код первого поколения представлен в приложении А.

=== Второе поколение
Во втором (финальном) поколении нейронной сети необходимо доработать первое поколение так, чтобы убрать нестабильность на проверке, которую давали слои пакетной нормализации; усилить распознавание нерезкости как самой слабой части модели и сделать контроль обучения более прозрачным за счёт расширенного набора метрик и автоматического построения графиков.

В первом поколении каждая голова представляла собой 1 нейрон. По результатам первой проверки именно нерезкость распознавалась хуже остальных: точность по blur на проверке была заметно ниже (около 0.75), тогда как under/over были около 0.87–0.88. Это объяснимо: нерезкость проявляется в тонких деталях (высоких частотах), и для её отделения от требуется более сложная нелинейная комбинация признаков, чем для экспозиционных дефектов, которые сильнее зависят от распределения яркостей.

Поэтому во втором для головы, отвечающей за размытие, добавлена цепочка слоёв 64 -> 32 -> 16 -> 1 с ReLU-активацией и Dropout 0.15. Для under/over усиление более умеренное: 32 -> 16 -> 1 и Dropout 0.1. Такой перекос по мощности сделан осознанно: вычислительная цена растёт незначительно (эти слои стоят после глобального пуллинга и работают с вектором признаков), но модель получает возможность построить более сложную границу решения именно для blur - там, где первое поколение было слабее.

Вторая важная доработка касается устойчивости дообучения основы. В первом поколении при размораживании EfficientNet график функции потерь заметно "скакал", что связано с BatchNorm. Во втором поколении эта проблема решена двумя мерами одновременно. Во-первых, на этапе тонкой настройки BatchNorm-слои принудительно замораживаются (их параметры и статистики перестают обновляться). Во-вторых, размораживается не вся основа, а только её верхняя часть: все слои, кроме последних примерно 40, оставляются замороженными. Тем самым сохраняются универсальные низкоуровневые признаки (контуры, текстуры), а адаптация идёт за счёт верхних слоёв, которые отвечают за более сложные комбинации признаков. Дополнительно уменьшается скорость обучения на втором этапе до 5*10^(-5), чтобы изменения весов были плавными и не приводили к деградации на проверке. В результате проверочные кривые становятся заметно более стабильными: на итоговом графике нет резких провалов val_loss, а к концу обучения значения сходятся к небольшим величинам. Графики обучения представлены на рисунке @второе-графики.

#рис(image("../материалы/второе_поколение_training_curves.png", width: 70%))[ Графики ключевых метрик второго поколения ] <второе-графики> 

Третья группа изменений - расширение набора метрик и улучшение журналирования. В первом поколении была только общая AUC, и по ней сложно понять, какая из голов учится хуже и почему. В конце концов скрипт по точности предсказаний дал понять, что самый слабый выход - выход по резкости, но такая проверка на выходе дает слабое представление о том, как каждая из голов обучалась. Во втором поколении добавлены метрики бинарной кросс-энтропии, посчитанной отдельно по каждому выходу. Новые графики также можно наблюдать на рисунке @второе-графики.

Финальные числа показывают, что доработки дали существенный прирост и по общим метрикам, и по каждой голове. В конце обучения получены значения: AUC на обучении 0.9959, AUC на проверке 0.9822, при этом проверочные потери составили val_loss = 0.0833. Финальные метрики представлены на рисунке @журнал-второе.

#рис(image("../материалы/второе_поколение.jpg", width: 80%))[ Значения loss и AUC второго поколения ] <журнал-второе>

Отдельный скрипт оценки на проверочной выборке показывает прикладные метрики качества при порогах 0.5 для всех голов. Общая точность по всем меткам (micro-accuracy) составила 0.9713, а точность строгого совпадения трёх меток одновременно (exact-match accuracy - доля изображений, где верно угаданы сразу все три метки) составила 0.9179. По дефектам получены следующие показатели. Для blur: precision 0.9946, recall 0.9866, F1 0.9906, accuracy 0.9953 (precision - доля правильных среди всех срабатываний, recall - доля найденных дефектов среди всех реальных дефектов). Для under: precision 0.7709, recall 0.7986, F1 0.7845, accuracy 0.9440 - видно, что именно under даёт основную часть ложных срабатываний (FP=271), поэтому его точность ниже. Для over: precision 0.9241, recall 0.8604, F1 0.8911, accuracy 0.9744, то есть пересвет распознаётся уверенно, но чуть хуже blur. Результаты проверки точности представлены на рисунке @второе-точность.

#рис(image("../материалы/второе_поколение_accuracy_доп.jpg", width: 80%))[ Точность предсказаний второго поколения ] <второе-точность>

С учётом полученных значений дальнейшее обучение в рамках практики не выглядит необходимым. Во-первых, модель уже достигла высокого уровня разделения классов на проверке (val_auc 0.9822) и высокой практической точности по всем меткам (micro-accuracy 0.9713), а графики показывают выход метрик на плато без признаков систематического улучшения к концу 10-й эпохи. Во-вторых, после стабилизации BatchNorm и частичного дообучения основы дальнейшие эпохи с большой вероятностью дадут убывающую отдачу и увеличат риск переобучения под синтетические искажения. В-третьих, наиболее действенный способ повышения качества теперь лежит не в увеличении числа эпох, а в настройке порогов по головам (особенно для under, чтобы снизить ложные срабатывания). 

Отдельно стоит обсудить метрику under. У метки under много ложноположительных срабатываний (FP=271), особено в сравнении с другими выходами. Поэтому её точность ниже (precision 0.7709 при accuracy 0.9440). Чаще всего это ночные сцены: кадр намеренно тёмный, но модель, обученная на синтетическом затемнении, воспринимает это как недосвет. Чтобы не браковать ночные фото, в приложении будет предусмотрено отключение фильтрации по under (или перевод в режим подсказки). Повышать under/over только дальнейшим обучением на текущей синтетике неэффективно из-за доменного разрыва и отсутствия контекстной разметки "ночь — норма". Для over эта проблема тоже прослеживается, но не так явно, потому что "естественные" затемнения в реальном мире встречаются намного чаще сильных пересветов. Есть смысл дорабатывать поведение программно уже в прикладном приложении: прежде всего порогами или пользовательской настройкой.

Таким образом, второе поколение можно считать финальным для этапа преддипломной практики: устранена нестабильность проверки, усилена самая слабая голова (blur), добавлен детальный контроль обучения по метрикам, а итоговые числа подтверждают, что модель уже подходит для встраивания в дипломное приложение.

Программный код второго поколения представлен в приложении А.