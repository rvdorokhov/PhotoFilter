#import "@local/gost732-2017:0.4.2": *
#import "@local/bmstu:0.3.0": *

= Подготовка датасета
== Выбор источника размеченных фотографий
Для обучения нейронной сети, определяющей технические дефекты фотографий, требуется набор данных с большим количеством изображений и корректной разметкой по целевым дефектам. При этом важно, чтобы разметка отражала именно техническое качество (нерезкость, недосвет, пересвет), а не смысл или «удачность» сцены. То есть разметка должна быть результатов не субъективной оценки "нравится"/"не нравится" опрошенных людей. На практике получить такой набор данных непросто: ручная разметка тысяч фотографий требует значительных трудозатрат и остаётся частично субъективной, особенно в пограничных случаях.

При формировании данных возможны два подхода. Первый - использование реальных датасетов с оценками качества. Такие наборы ближе к реальным пользовательским условиям, однако часто содержат только общую оценку качества без явного указания типа дефекта. Кроме того, часть датасетов ориентирована на «эстетическую» (т.е. субъктивную) оценку, что усложняет выделение конкретных технических причин брака. 

Второй подход - формирование синтетического датасета на основе исходных качественных изображений, когда к «чистым» фотографиям программно добавляются контролируемые искажения (размытие, изменение яркости и т.п.). В этом случае разметка формируется автоматически и не зависит от субъективной оценки, можно получить достаточное число примеров каждого дефекта, управлять силой дефекта через уровни искажений и обеспечивать воспроизводимость экспериментов.

С учётом ограничений преддипломной практики (необходимость быстро получить достаточный объём данных с однозначной разметкой) более рациональным является второй подход - обучение на синтетических искажениях.

\
\
\

В качестве источника данных выбран датасет KADIS-700K. Он содержит исходные изображения и большое число их версий с искусственно добавленными искажениями различных типов и уровней. Это позволяет сформировать выборку, напрямую соответствующую поставленной задаче: выделить только те типы искажений, которые моделируют нерезкость (размытие/смаз), недосвет и пересвет, и автоматически сформировать разметку для обучения нейронной сети.

KADIS-700K — крупный синтетический набор для оценки качества изображений. Он включает около 140 000 исходных (неискажённых) изображений и примерно 700 000 искажённых: для каждого исходного изображения подготовлено несколько вариантов, полученных добавлением искажений, выбираемых из набора 25 типов с 5 уровнями выраженности. Набор искажений формируется с помощью кода генерации искажений (Matlab), что позволяет точно знать тип и уровень добавленного дефекта.

В рамках дипломного проекта, конечно, рассматриваются только три дефекта, и поэтому в обучении не будут участвовать все 840 000 изображений, но на их базе можно сформировать достаточную выборку изображений с нужными дефектами. Из всего спектра искажений KADIS-700K используются только следующие типы:

1) нерезкость/смаз: lens blur (dist_type = 2) и motion blur (dist_type = 3);

2) пересвет: brighten (dist_type = 16);

3) недосвет: darken (dist_type = 17).


\
\
\
\
\
\
\
\
\

== Генерация искаженных изображений
Для формирования обучающей выборки на основе KADIS-700K использовался исходный скрипт генерации, поставляемый вместе с кодом добавления искажений (code_imdistort) и функцией imdist_generator. В оригинальном варианте скрипт последовательно проходил по списку исходных изображений из файла kadis700k_ref_imgs.csv, считывал каждое изображение из каталога ref_imgs/ и для заданного типа искажения генерировал все пять уровней (от 1 до 5). Исходный код добавления искажений представлен в листинге @матлаб-исходник.

#листинг(```
%% setup
clear; clc;
addpath(genpath('code_imdistort'));


%% read the info of pristine images

tb = readtable('kadis700k_ref_imgs.csv');
tb = table2cell(tb);

%% generate distorted images in dist_imgs folder

for i = 1:size(tb,1)
    ref_im = imread(['ref_imgs/' tb{i,1}]);
    dist_type = tb{i,2};
    
    for dist_level = 1:5
        [dist_im] = imdist_generator(ref_im, dist_type, dist_level);
        strs = split(tb{i,1},'.');
        dist_im_name = [strs{1}  '_' num2str(tb{i,2},'%02d')  '_' num2str(dist_level,'%02d') '.bmp'];
        disp(dist_im_name);
        imwrite(dist_im, ['dist_imgs/' dist_im_name]);
    end
    
end
```)[ Исходный код добавления искажений ] <матлаб-исходник>

В рамках преддипломной практики данный скрипт был адаптирован под задачи дипломного проекта. Во-первых, из полного набора искажений KADIS-700K были оставлены только те, которые соответствуют целевым дефектам. Для этого после чтения таблицы выполнялась фильтрация по dist_type, и дальнейшая генерация выполнялась только для типов 2, 3, 16 и 17. 

Во-вторых, вместо перебора всех уровней искажения для каждого изображения уровни выбирались случайно из заранее заданных допустимых наборов, что позволило сконцентрировать данные на более заметных дефектах и избежать слабых искажений, которые хуже соответствуют практическим ситуациям. Использовались следующие диапазоны: для dist_type = 2 уровни [2, 3, 4], для dist_type = 3 уровни [4, 5], для dist_type = 16 уровни [4, 5], для dist_type = 17 уровни [4, 5].

В-третьих, изменён формат сохранения искажённых изображений. Вместо исходного расширения .bmp результаты сохранялись в .jpg с параметром качества 95. Такой выбор сделан для приближения данных к реальным пользовательским фотографиям (в большинстве случаев они хранятся в JPEG), а также для ускорения чтения с диска и уменьшения занимаемого объёма памяти. Имена файлов формировалисьпо схеме name_XX_YY.jpg, где к базовому имени исходного файла добавлялись код типа искажения XX и уровень YY, записанные в двухзначном формате.

Дополнительно в скрипт были внесены проверки, повышающие устойчивость генерации. Если целевой файл уже существует в dist_imgs/, генерация пропускается, что позволяет безопасно перезапускать процесс без перезаписи уже сформированных данных. К тому же это позволило снизить избыточную корреляцию в данных: если сохранять множество вариантов одной и той же сцены, модель может переобучаться на характерные детали конкретного изображения и демонстрировать завышенные метрики, вместо устойчивого распознавания дефектов на разных сценах.

Модифицированный код представлен в листинге @матлаб-модификация и в приложении А.

#листинг(```
%% setup
clear; clc;
addpath(genpath('code_imdistort'));

fid = fopen('labels.csv','w');
fprintf(fid, 'path,blur,under,over,dist_type,dist_level,ref\n');

tb = readtable('kadis700k_ref_imgs.csv');

% --- ОСТАВЛЯЕМ ТОЛЬКО НУЖНЫЕ ИСКАЖЕНИЯ ---
types = [2 3 16 17];            % gaussian/lens/motion blur + brighten + darken
tb = tb(ismember(tb{:,2}, types), :);  % 2-й столбец = dist_type

tb = table2cell(tb);

ref_list = unique(tb(:,1)); 

for r = 1:numel(ref_list)
    ref_name = ref_list{r};
    ref_path = fullfile('ref_imgs', ref_name);

    % дефектов нет
    blur = 0; under = 0; over = 0;
    dist_type = 0; dist_level = 0;

    fprintf(fid, '%s,%d,%d,%d,%d,%d,%s\n', ref_path, blur, under, over, dist_type, dist_level, ref_name);
end


%% generate distorted images in dist_imgs folder

for i = 1:size(tb,1)
    ref_im = imread(fullfile('ref_imgs', tb{i,1}));
    dist_type = tb{i,2};

    if dist_type == 2
        allowed_levels = [2 3 4];
    elseif dist_type == 3
        allowed_levels = [4 5];
    elseif dist_type == 16
        allowed_levels = [4 5];
    elseif dist_type == 17
        allowed_levels = [4 5];
    else
        continue;
    end
    
  %%  for k = 1:numel(keep_levels)
        dist_level = allowed_levels(randi(numel(allowed_levels)));

        dist_im = imdist_generator(ref_im, dist_type, dist_level);

        % имя файла остаётся совместимым: _тип_уровень.bmp
        strs = split(tb{i,1},'.');

        dist_im_name = [strs{1} '_' num2str(dist_type,'%02d') '_' num2str(dist_level,'%02d') '.jpg'];
        out_path = fullfile('dist_imgs', dist_im_name);

        if exist(out_path, 'file')
            continue;
        end
        
        imwrite(dist_im, out_path, 'Quality', 95);

        % вычисляем метки по dist_type
        blur = 0; under = 0; over = 0;
        if dist_type == 2 || dist_type == 3
            blur = 1;
        elseif dist_type == 17
            under = 1;
        elseif dist_type == 16
            over = 1;
        end
       
        fprintf(fid, '%s,%d,%d,%d,%d,%d,%s\n', out_path, blur, under, over, dist_type, dist_level, tb{i,1});

 %%   end
end

fclose(fid);

```)[ Модифицированный код добавления искажений ] <матлаб-модификация>

В результате выполненной модификации был реализован воспроизводимый процесс генерации искажённых изображений, который формирует только те варианты, что соответствуют выбранным дефектам дипломного проекта, и сохраняет их в формате, близком к условиям практического использования в приложении.

\

== Разметка датасета
После генерации искажённых изображений был сформирован единый файл разметки labels.csv, содержащий пути к изображениям и целевые метки дефектов. Для дальнейшего обучения нейронной сети требовалось разделить данные на обучающую и валидационную выборки так, чтобы оценка качества была корректной и не завышалась из-за попадания в обе выборки разных версий одной и той же сцены.

Разделение «по строкам» в данном случае является нежелательным, так как в датасете присутствуют несколько вариантов одного исходного изображения (исходное и искажённые версии). Если часть вариантов одной сцены окажется в обучающей выборке, а другая часть — в валидационной, нейронная сеть может демонстрировать завышенные метрики за счёт узнавания особенностей конкретной сцены, а не за счёт устойчивого распознавания дефектов. Чтобы избежать такой утечки, разделение выполнялось не по отдельным файлам, а по идентификатору исходного изображения.

В разметке для этого используется поле ref, которое хранит имя исходного файла и тем самым группирует все варианты одной сцены. В скрипте сначала загружается labels.csv, затем выполняется разделение по уникальным значениям ref. Множество исходных сцен случайно разбивается на две части в пропорции 80/20. После этого строки, относящиеся к выбранным ref, собираются в train_df, а остальные — в val_df. Полученные таблицы сохраняются в файлы train.csv и val.csv.

Скрипт, разделяющий датасет на обучающую и валидационную выборки содержится в @скрипт-разметка и в приложении A.

#листинг(```
import os
import pandas as pd
from sklearn.model_selection import train_test_split

LABELS_PATH = "labels.csv"
TRAIN_OUT = "train.csv"
VAL_OUT = "val.csv"
VAL_RATIO = 0.2
SEED = 42

df = pd.read_csv(LABELS_PATH)

df["path"] = df["path"].astype(str).str.replace("\\", os.sep).str.replace("/", os.sep)

# Сплит по ref (чтобы не было утечки)
refs = df["ref"].astype(str).unique()
train_refs, val_refs = train_test_split(refs, test_size=VAL_RATIO, random_state=SEED, shuffle=True)

train_df = df[df["ref"].astype(str).isin(train_refs)].reset_index(drop=True)
val_df   = df[df["ref"].astype(str).isin(val_refs)].reset_index(drop=True)

train_df.to_csv(TRAIN_OUT, index=False)
val_df.to_csv(VAL_OUT, index=False)

print("Saved:", TRAIN_OUT, len(train_df))
print("Saved:", VAL_OUT, len(val_df))
print("Unique refs train/val:", len(train_refs), len(val_refs))
```)[ Скрипт, разделяющий датасет на обучающую и валидационную выборки ] <скрипт-разметка>

В результате такой процедуры обеспечивается отсутствие пересечения сцен между выборками: одна и та же исходная фотография и её искажённые версии могут принадлежать только обучающей или только валидационной части. Это позволяет получить более честную оценку качества нейронной сети и избежать завышения метрик из-за утечки данных. В результате мы получили готовый разделенный датасет, включающий в себя как данные, так и разметку.